{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "f371e8b9-43d2-40e5-8473-1d3fb793816a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "41aec9e7",
    "execution_start": 1649085118697,
    "execution_millis": 785362,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 225
   },
   "source": "#load in the data\n#split data into training and validation data\n#use training data to run different evaluation\n#evaluate performance on validation data\n#different classifiers could be: knearestneighbors (with different neighbors, decisiontreeclasifier)\n#analyse results by comparing classifiers on different metrics, inspecting images that are classifies incorrectly etc\n#select best classifier (by which rules should we select)\n#create python script that takes an image, measures the features, classifies the image\n#and gives its probability of being a melanoma (range from 0 to 1)",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Features\n\n* Perimeter\n* Area\n* Compactness\n* Assymetry\n* !color",
   "metadata": {
    "cell_id": "e9e617954d454ebbb91e29c37fe84f17",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 223.984375
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "1fbb2120443e41a7886d5f07c06ad5f4",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e50ec7a6",
    "execution_start": 1649085118698,
    "execution_millis": 3107,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 297
   },
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport Config\nfrom PIL import Image \nimport os, Config\nfrom skimage import morphology\nfrom statsmodels.robust import mad\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "5b5fe856f14e4f4c98da8ce907751b58",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2f7406a1",
    "execution_start": 1649085121814,
    "execution_millis": 3,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 153
   },
   "source": "def load_picture(iid):\n    path_mask = '../data/example_segmentation'\n    file_mask = path_mask + os.sep + image_id[iid] + '_segmentation.png'\n    picture = Image.open(file_mask)\n    return picture",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class Picture:\n    def __init__(self, img, img_bw):\n        self.img = img\n        self.img_bw = img_bw\n\n    #ASSYMETRY\n\n\n    def _assymetry(self, rot_img):\n        ''' get the assymetry between the left and right part of a given binary mask '''\n        width, height = rot_img.size #mask should be quadratic and therefore have equal dimension\n        size = width * height\n\n        #check for uneven number of pixels (should not happen but just as a precaution)\n        if width %2 != 0:\n            raise TypeError(\"Uneven number of pixel and cannot be symmetric\")\n        \n        #cut in half and fold\n        left = rot_img.crop((0, 0, (width/2), height)) #left part of picture (left, top, right, bottom)\n        right = rot_img.crop(((width/2), 0, width, height)) #right part of picture\n        right = right.transpose(Image.FLIP_LEFT_RIGHT) #flip right part to compare\n\n        #get the binary difference between left an right\n        symmetry = np.where(np.array(left) != np.array(right), 1, 0)\n\n        return np.sum(symmetry) / (size/2) #the percentage of assymetry \n    \n    def get_assymetry(self):\n        ''' get the assymetry for a given mask by folding it in half from multiple angles'''\n        return round(np.mean([self._assymetry(self.img_bw), self._assymetry(self.img_bw.rotate(30, expand= True)),self._assymetry(self.img_bw.rotate(60, expand= True)),self._assymetry(self.img_bw.rotate(90, expand= True))]),2)\n\n    #BORDER\n    def measure_area_perimeter(self): #Stolen from Veronika's github\n    # Measure area: the sum of all white pixels in the mask image\n        mask = np.where(np.array(self.img_bw)==255, 1, 0)\n        area = np.sum(mask)\n\n        # Measure perimeter: first find which pixels belong to the perimeter.\n        struct_el = morphology.disk(1)\n        mask_eroded = morphology.binary_erosion(mask, struct_el)\n        image_perimeter = mask - mask_eroded\n\n        # Now we have the perimeter image, the sum of all white pixels in it\n        perimeter = np.sum(image_perimeter)\n\n        return area, perimeter\n\n    def get_compactness(self):\n        ''' Computes and returns the compactness of a figure '''\n        area, perimeter = self.measure_area_perimeter()\n        return round(4*np.pi*area / perimeter ** 2, 4)\n\n\n    #COLOR\n    def get_color_variability(self):\n        '''\n            Assigns a color variability score\n        '''\n        if self._check_variability() < 20: \n            return 0 \n        elif self._check_variability() < 50: \n            return 1\n        else: \n            return 2\n\n    def _check_variability(self):\n        '''\n            Returns a mean of the median absolute deviation of each color (rgb)\n        '''\n        self.img[self.img_bw==0] = 0\n        \n        #we then calculate the mad of each dimension \n        r, g, b = self.img[:,:,0], self.img[:,:,1], self.img[:,:,2]\n        mad_r= mad(r[np.where(r != 0)])\n        mad_g= mad(g[np.where(g != 0)])\n        mad_b= mad(b[np.where(b != 0)])\n        mad_result= [mad_r,mad_g,mad_b]\n\n        #calculating the mean\n        return np.mean(mad_result)",
   "metadata": {
    "cell_id": "c089d943d601481b867586cb7df50aa5",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7cf7bc40",
    "execution_start": 1649085121820,
    "execution_millis": 41,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1503
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "def cut_image(picture):\n    width, height = picture.size\n    image = np.array(picture)\n    \n    if width %2 != 0:\n        image = np.delete(image, -1, 1)\n\n    if height %2 != 0:\n        image = np.delete(image, -1, 0)\n\n    image = Image.fromarray(image)\n\n    return image",
   "metadata": {
    "cell_id": "1e9c8d4ba5194b7086f7654d095ae85a",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2bb3b7ed",
    "execution_start": 1649085121862,
    "execution_millis": 1,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 297
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "def get_row(pict, pic):  \n    assym = pict.get_assymetry()\n    comp = pict.get_compactness()\n    color = pict.get_color_variability()\n\n    melanoma = groundtruth[groundtruth['image_id'] == pic]['melanoma'].iloc[0]\n    return pd.DataFrame([[pic, assym, comp, color, melanoma]], \n                        columns=['ISIC', 'Assymetry', 'Compactness', 'Color', 'Melanoma'], \n                        index=[pic])\n",
   "metadata": {
    "cell_id": "fa907fd376584ff1918a2d41aca4906a",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f70d131",
    "execution_start": 1649085121866,
    "execution_millis": 5,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 243
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "def train_evaluate_classifiers(df):\n    testies = df\n\n    X = testies[[\"Assymetry\", \"Compactness\",\"Color\"]]\n    y = testies[\"Melanoma\"]\n\n    #split data set into a train, test and valification set\n    X_dev, X_test, y_dev, y_test = train_test_split(\n        X, y, test_size= 0.3, stratify=y, random_state=0)\n\n    X_train, X_val, y_train, y_val = train_test_split(\n        X_dev, y_dev, test_size= 0.5, stratify=y_dev)\n\n    #train a classifier\n    knn1 = KNeighborsClassifier(n_neighbors=1)\n    knn1trained = knn1.fit(X_train, y_train)\n\n    knn3 = KNeighborsClassifier(n_neighbors=3)\n    knn3trained = knn3.fit(X_train, y_train)\n\n    knnlog = KNeighborsClassifier(n_neighbors=np.log(len(df[\"Melanoma\"])))\n    knnlogtrained = knnlog.fit(X_train, y_train)\n\n    tree = DecisionTreeClassifier()\n    treetrained = tree.fit(X_train, y_train)\n    \n    gauss = GaussianNB()\n    gausstrained = gauss.fit(X_test, y_test)\n\n    #evaluate the classifiers\n    y_val_knn1 = knn1trained.predict(X_val)\n    y_val_knn3 = knn3trained.predict(X_val)\n    y_val_knnlog = knnlogtrained.predict(X_val)\n    y_val_tree = treetrained.predict(X_val)\n    y_val_gauss = gausstrained.predict(X_val)\n\n    print(\"Accuracy (using numpy)\")\n    print(f\"knn 1: {np.sum(y_val_knn1 == y_val)/ np.size(y_val)*100}\")\n    print(f\"knn 3: {np.sum(y_val_knn3 == y_val)/ np.size(y_val)*100}\")\n    print(f\"knn log: {np.sum(y_val_knnlog == y_val)/ np.size(y_val)*100}\")\n    print(f\"tree: {np.sum(y_val_tree == y_val)/ np.size(y_val)*100}\")\n    print(f\"gauss: {np.sum(y_val_gauss == y_val)/ np.size(y_val)*100}\")\n\n    print(\"Accuracy score\")\n    print(f\"knn 1: {accuracy_score(y_val,y_val_knn1)}\")\n    print(f\"knn 3: {accuracy_score(y_val,y_val_knn3)}\")\n    print(f\"knn log: {accuracy_score(y_val,y_val_knnlog)}\")\n    print(f\"tree: {accuracy_score(y_val,y_val_tree)}\")\n    print(f\"gauss: {accuracy_score(y_val,y_val_gauss)}\")\n\n    print(\"roc auc score\")\n    print(f\"knn1: {roc_auc_score(y_val, y_val_knn1)}\")\n    print(f\"knn3: {roc_auc_score(y_val, y_val_knn3)}\")\n    print(f\"knnlog: {roc_auc_score(y_val, y_val_knnlog)}\")\n    print(f\"tree: {roc_auc_score(y_val, y_val_tree)}\")\n    print(f\"gauss: {roc_auc_score(y_val, y_val_gauss)}\")\n\n    \n",
   "metadata": {
    "cell_id": "e22034dc29504dfa9e026ac22c9b5167",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "577bd4ad",
    "execution_start": 1649085900775,
    "execution_millis": 19,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 1125
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": "    > Load the CSV with ISIC names and \"ground truth\"\n    > Start adding features to the data frame\n    > Split the data frame into testing and training - start training\n    > Train a classifier\n        - Nearest neighbour with k neighbours\n        - Decision tree\n        - Bayes classifier\n    ",
   "metadata": {
    "cell_id": "9d276ffec5544cfab41e50b4a3bf9229",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 195.578125
   }
  },
  {
   "cell_type": "code",
   "source": "groundtruth = pd.read_csv(Config.example_ground_truth_path)",
   "metadata": {
    "cell_id": "5da5e2be02da4bbebd48babf78ef7164",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2e77069b",
    "execution_start": 1649085902309,
    "execution_millis": 4,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 81
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": "def main():\n\n    image_names = [ID for ID in groundtruth['image_id']]\n\n    features_df = pd.DataFrame(columns=['ISIC', 'Assymetry', 'Compactness', 'Color', 'Melanoma'])\n    for pic in image_names[0:50]:\n        img_bw = Image.open(Config.mask_path + os.sep + pic + '_segmentation.png') # open mask image\n        img_bw = cut_image(img_bw)\n\n        img = plt.imread(Config.images_path + os.sep + pic + '.jpg') # open image\n        pict = Picture(img = img, img_bw = img_bw)\n        \n        tempdf = get_row(pict, pic)\n        features_df.append(tempdf)\n\n    train_evaluate_classifiers(features_df)\n\n    ",
   "metadata": {
    "cell_id": "1f404f7d29b84c45882186c4e5b6a90e",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a103fdb8",
    "execution_start": 1649085902478,
    "execution_millis": 0,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 387
   },
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": "main()",
   "metadata": {
    "cell_id": "256e9dd7085647039affdb8a53a1ee65",
    "tags": [],
    "deepnote_to_be_reexecuted": false,
    "source_hash": "286a4539",
    "execution_start": 1649085902633,
    "execution_millis": 124915,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 673
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-9fabb520342c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mfeatures_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtempdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain_evaluate_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-42d07e933892>\u001b[0m in \u001b[0;36mtrain_evaluate_classifiers\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#split data set into a train, test and valification set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     X_dev, X_test, y_dev, y_test = train_test_split(\n\u001b[0;32m----> 9\u001b[0;31m         X, y, test_size= 0.3, stratify=y, random_state=0)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     X_train, X_val, y_train, y_val = train_test_split(\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2421\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     )\n\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             \u001b[0;34m\"aforementioned parameters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         )\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.3 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "\"\"\"df = pd.DataFrame(columns=['ISIC', 'Assymetry', 'Compactness', 'Color', 'Melanoma'])\ndf2 = pd.DataFrame(\n        [[1, 2, 3, 4, 5]], \n        columns=['ISIC', 'Assymetry', 'Compactness', 'Color', 'Melanoma'], \n        index=['ISIC_101'])\ndf.append(df2)\"\"\"",
   "metadata": {
    "cell_id": "2c145c36d6604156b06d24ec1a0f9b7a",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "289d624f",
    "execution_start": 1649084369541,
    "execution_millis": 438,
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 208
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 11,
     "data": {
      "text/plain": "\"df = pd.DataFrame(columns=['ISIC', 'Assymetry', 'Compactness', 'Color', 'Melanoma'])\\ndf2 = pd.DataFrame(\\n        [[1, 2, 3, 4, 5]], \\n        columns=['ISIC', 'Assymetry', 'Compactness', 'Color', 'Melanoma'], \\n        index=['ISIC_101'])\\ndf.append(df2)\""
     },
     "metadata": {}
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "3c77ebdb2e294c0f9af934f914afeb5e",
    "tags": [],
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 66
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=932aa97b-f6d2-4889-8f04-d6166675cc2f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "96a06088-7956-4476-b86c-c3ba1b9f6d28",
  "deepnote_execution_queue": []
 }
}