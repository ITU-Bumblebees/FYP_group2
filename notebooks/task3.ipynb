{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "f371e8b9-43d2-40e5-8473-1d3fb793816a",
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 210
   },
   "source": "#load in the data\n#split data into training and validation data\n#use training data to run different evaluation\n#evaluate performance on validation data\n#different classifiers could be: knearestneighbors (with different neighbors, decisiontreeclasifier)\n#analyse results by comparing classifiers on different metrics, inspecting images that are classifies incorrectly etc\n#select best classifier (by which rules should we select)\n#create python script that takes an image, measures the features, classifies the image\n#and gives its probability of being a melanoma (range from 0 to 1)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Features\n\n* Perimeter\n* Area\n* Compactness\n* Assymetry\n* !color",
   "metadata": {
    "cell_id": "e9e617954d454ebbb91e29c37fe84f17",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 222
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "1fbb2120443e41a7886d5f07c06ad5f4",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 228
   },
   "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport Config\nfrom PIL import Image \nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "5b5fe856f14e4f4c98da8ce907751b58",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 138
   },
   "source": "def load_picture(iid):\n    path_mask = '../data/2k/example_segmentation'\n    file_mask = path_mask + os.sep + image_id[iid] + '_segmentation.png'\n    picture = Image.open(file_mask)\n    return picture",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def cut_image(image):\n    ''' Assures an image has even number of pixels '''\n    width, height = image.size\n    image = np.array(image)\n    \n    if width %2 != 0:\n        image = np.delete(image, -1, 1)\n\n    if height %2 != 0:\n        image = np.delete(image, -1, 0)\n\n    image = Image.fromarray(image)\n\n    return image",
   "metadata": {
    "cell_id": "3676b7140ee74103af317ae1d4aaf4d9",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 300
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def assymetry(mask):\n    ''' get the assymetry between the left and right part of a given binary mask '''\n    width, height = mask.size #mask should be quadratic and therefore have equal dimension\n    size = width * height\n\n    #check for uneven number of pixels (should not happen but just as a precaution)\n    if width %2 != 0:\n        raise TypeError(\"Uneven number of pixel and cannot be symmetric\")\n    \n    #cut in half and fold\n    left = mask.crop((0, 0, (width/2), height)) #left part of picture (left, top, right, bottom)\n    right = mask.crop(((width/2), 0, width, height)) #right part of picture\n    right = right.transpose(Image.FLIP_LEFT_RIGHT) #flip right part to compare\n\n    #get the binary difference between left an right\n    symmetry = np.where(np.array(left) != np.array(right), 1, 0)\n\n    return np.sum(symmetry) / (size/2) #the percentage of assymetry \n    ",
   "metadata": {
    "cell_id": "5a7659cce1f8498aa98b6ed4a4744c23",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 390
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def get_assymetry(image):\n    ''' get the assymetry for a given mask by folding it in half from multiple angles'''\n    return round(np.mean([assymetry(image), assymetry(image.rotate(30, expand= True)),assymetry(image.rotate(60, expand= True)),assymetry(image.rotate(90, expand= True))]),2)",
   "metadata": {
    "cell_id": "10d15bc042264e6b9bf0f9c66127fd88",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 102
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def compactness(p, A):\n    return round(4*np.pi*A / p ** 2, 4)",
   "metadata": {
    "cell_id": "55e45453ce51405689dcc6cb9756cab8",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 84
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "def get_features(iid):\n    ''' Computes all features for an image id eg. ISIC_19023 '''\n    image = load_picture(iid)\n    image = cut_image(image)\n    p, A = get_perim_area(image)\n    assym = assymetry(image)\n    comp = compactness(p, A)\n    prob = final_classifier(assym, comp, color)\n    ",
   "metadata": {
    "cell_id": "78a5ee8aae564513a7a9c831793cd6c0",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 246
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=932aa97b-f6d2-4889-8f04-d6166675cc2f' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "96a06088-7956-4476-b86c-c3ba1b9f6d28",
  "deepnote_execution_queue": []
 }
}